{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "commented_ysc_GPTRick.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c5e3d88b44b40b69cf0ae234c96993a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71a6cfecb5d34054b823c1599eef6930",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cc9dac7465841ad90b93b30aafa572c",
              "IPY_MODEL_b72bd198f0f649528d2165b9e1ac90eb"
            ]
          }
        },
        "71a6cfecb5d34054b823c1599eef6930": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cc9dac7465841ad90b93b30aafa572c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2cf060b2af94c21bf659a81301070dd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 641,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 641,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51bd8ec236b64eb89ea3a9cb3f277b53"
          }
        },
        "b72bd198f0f649528d2165b9e1ac90eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db3cd77ef1ea4c03b28de7348510a76c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 641/641 [00:00&lt;00:00, 1.26kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b3febcd04e24568bf825434e6b3acfd"
          }
        },
        "b2cf060b2af94c21bf659a81301070dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51bd8ec236b64eb89ea3a9cb3f277b53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db3cd77ef1ea4c03b28de7348510a76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b3febcd04e24568bf825434e6b3acfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f5589a430bc45de80bd165ce81f305a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a1d16f6766e49cea610310ca85dcb6b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f49f0677bd342d18f08c0a74521bf70",
              "IPY_MODEL_38f96a939f0243f39b1e8300123bcf44"
            ]
          }
        },
        "5a1d16f6766e49cea610310ca85dcb6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f49f0677bd342d18f08c0a74521bf70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fed25d59cda34dc18d733301f9d8a8e9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_546c06b807ab4316936d8f6abf659ae1"
          }
        },
        "38f96a939f0243f39b1e8300123bcf44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e4750183de34f419c194321aae27a1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 7.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0052b4b9b7164007a9d753c898120416"
          }
        },
        "fed25d59cda34dc18d733301f9d8a8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "546c06b807ab4316936d8f6abf659ae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e4750183de34f419c194321aae27a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0052b4b9b7164007a9d753c898120416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b68273caafc24f4abb0c7fcc05dc09cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c9465ecfc4c4799a95ba1be32b49303",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a671c221ace8404cbd038d6d235a752e",
              "IPY_MODEL_8917459b75bc45e0a531f3b74f269b40"
            ]
          }
        },
        "0c9465ecfc4c4799a95ba1be32b49303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a671c221ace8404cbd038d6d235a752e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_413000bbce49447aa6df57c40c9bdb3b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d70a2eeda98406f8b3daa1637d31739"
          }
        },
        "8917459b75bc45e0a531f3b74f269b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_96c9010ea8e64274bc55636523285ec8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.65MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b35bceabb184f08910be674a2dbd07f"
          }
        },
        "413000bbce49447aa6df57c40c9bdb3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d70a2eeda98406f8b3daa1637d31739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96c9010ea8e64274bc55636523285ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b35bceabb184f08910be674a2dbd07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44ca7868ae564a5287970401b0900f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_675f031444a74397b0e73291db89e50e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cef977fccf04ba59cbce0fbd4bdf9ba",
              "IPY_MODEL_de94a1f0690d4172b8467a7ccdf5a537"
            ]
          }
        },
        "675f031444a74397b0e73291db89e50e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cef977fccf04ba59cbce0fbd4bdf9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e1d6cf576e1642ef82d116fa20ee3bc7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 26,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a9775e2f11540c6845e6aeaca6abbff"
          }
        },
        "de94a1f0690d4172b8467a7ccdf5a537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc1d946ed0864f428ef5566b9ad4c5ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26.0/26.0 [00:00&lt;00:00, 252B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d89875bccc0243869cbbc9f5dbe8682f"
          }
        },
        "e1d6cf576e1642ef82d116fa20ee3bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a9775e2f11540c6845e6aeaca6abbff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc1d946ed0864f428ef5566b9ad4c5ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d89875bccc0243869cbbc9f5dbe8682f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b8c1f8d9af04e8bb33a735853b65f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4aa00b564aa4426bb050b093b4092cfa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e064a6b9f1504fd087f6d87e2f0fc837",
              "IPY_MODEL_c54fccc393e64c7d9bd75ae593868ec2"
            ]
          }
        },
        "4aa00b564aa4426bb050b093b4092cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e064a6b9f1504fd087f6d87e2f0fc837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_52e02cd3b1fb40a0961e3bd461a657eb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 351265583,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 351265583,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_baa2283fc5b74753a8d1c0dc15e20377"
          }
        },
        "c54fccc393e64c7d9bd75ae593868ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_990b6938625f434e9271cf48c2f59911",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 351M/351M [00:08&lt;00:00, 39.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82e170dc62624b298805f0c631b4af22"
          }
        },
        "52e02cd3b1fb40a0961e3bd461a657eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "baa2283fc5b74753a8d1c0dc15e20377": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "990b6938625f434e9271cf48c2f59911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82e170dc62624b298805f0c631b4af22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5aab8b98fdf741428fda6a2936a6c32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b581bbe998324e4198b54f1b33fa8fcb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff9f00d7a67b4a0d944299166c3943e5",
              "IPY_MODEL_0bc945b69eff441db1bb7be22c0896f9"
            ]
          }
        },
        "b581bbe998324e4198b54f1b33fa8fcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff9f00d7a67b4a0d944299166c3943e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_475d496b15b343448e7463cdcf9463a4",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e34e242a73ac4f4887f3d16d651affdf"
          }
        },
        "0bc945b69eff441db1bb7be22c0896f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b2c9710105a6405f9de235c41ed39a50",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [11:37&lt;00:00, 232.56s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62d6b4a4ad454316bcceb04ecb55821b"
          }
        },
        "475d496b15b343448e7463cdcf9463a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e34e242a73ac4f4887f3d16d651affdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2c9710105a6405f9de235c41ed39a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62d6b4a4ad454316bcceb04ecb55821b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e1d23ba00644b80b8b4b5ee6a5abb6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f3f630db29349da9afb5b7479f4aaf2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b69f24d60bfe4bd7a50cb9465505e0dc",
              "IPY_MODEL_74fad213012043dcaa370dc2e54de8bc"
            ]
          }
        },
        "4f3f630db29349da9afb5b7479f4aaf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b69f24d60bfe4bd7a50cb9465505e0dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4bf0d712c8564501b202165d1e0033d5",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 427,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19f2b118a7db4bc292c06d94c2760590"
          }
        },
        "74fad213012043dcaa370dc2e54de8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee6446c4023c48518fd58b833e1a594e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 427/427 [11:37&lt;00:00,  1.63s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c99fa5c01fe4478aa8e57b7d59e11c29"
          }
        },
        "4bf0d712c8564501b202165d1e0033d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19f2b118a7db4bc292c06d94c2760590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee6446c4023c48518fd58b833e1a594e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c99fa5c01fe4478aa8e57b7d59e11c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "136a63d66eb44cccbcd66bf4c0535a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1b239d3d3f14906934461eb66c1c0f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f326022eebe1428daab12fab05c8a075",
              "IPY_MODEL_c4091ab4f5264a86a149793853dbb941"
            ]
          }
        },
        "b1b239d3d3f14906934461eb66c1c0f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f326022eebe1428daab12fab05c8a075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0f8864b0bf74deab8240b716dbda564",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 427,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cb73064ba3545d0815cef04dba25f40"
          }
        },
        "c4091ab4f5264a86a149793853dbb941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6fa8a5e40b74a4199ab785729880b39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 427/427 [06:20&lt;00:00,  1.12it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57b31670fc3a40839a6004c6aa0e41a5"
          }
        },
        "a0f8864b0bf74deab8240b716dbda564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cb73064ba3545d0815cef04dba25f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6fa8a5e40b74a4199ab785729880b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57b31670fc3a40839a6004c6aa0e41a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2109878b39849a799187136beadf144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_36d501a1ff37420eadef5bcd7297ee26",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0a76fe2605c84745b42f9cdb5f1a52db",
              "IPY_MODEL_2dfb4d0fc09645118f830e4ebc5dfdd0"
            ]
          }
        },
        "36d501a1ff37420eadef5bcd7297ee26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a76fe2605c84745b42f9cdb5f1a52db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5b6f22c0ea24860a93cbe6a6edfc05e",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 427,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69bbca8e234e48fbbc389fd44e11624f"
          }
        },
        "2dfb4d0fc09645118f830e4ebc5dfdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02bc54995de148238eb5ed06f2ea8d62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 427/427 [03:53&lt;00:00,  1.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_270e2a3848324fb5996af60d6ef26366"
          }
        },
        "f5b6f22c0ea24860a93cbe6a6edfc05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69bbca8e234e48fbbc389fd44e11624f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02bc54995de148238eb5ed06f2ea8d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "270e2a3848324fb5996af60d6ef26366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6296e303aed34c01866caffc200c0cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60eabd58645142aea72ae027b057d65d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9d9f452aa79048599819ad5cc759a5e5",
              "IPY_MODEL_d4e4ccce098941459c4409187201979d"
            ]
          }
        },
        "60eabd58645142aea72ae027b057d65d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d9f452aa79048599819ad5cc759a5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d57f56580d244a59ad388adb33abcb4d",
            "_dom_classes": [],
            "description": "Evaluating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 47,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 47,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37e11da84adb4832842d9a9ce54c2c2b"
          }
        },
        "d4e4ccce098941459c4409187201979d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_822d24db536f4994af65dd764364695c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 47/47 [10:08&lt;00:00, 12.96s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1391f67de61c40f1aa24fd267c1f70d9"
          }
        },
        "d57f56580d244a59ad388adb33abcb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37e11da84adb4832842d9a9ce54c2c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "822d24db536f4994af65dd764364695c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1391f67de61c40f1aa24fd267c1f70d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ychocci/gpt2_pretrain/blob/main/commented_ysc_GPTRick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KrNfVNueNhR"
      },
      "source": [
        "#Make your own Rick Sanchez (bot) with Transformers and DialoGPT fine-tuning\n",
        "\n",
        "by [Rostyslav Neskorozhenyi](https://www.linkedin.com/in/slanj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78afhsngLZMw"
      },
      "source": [
        "I am a big fan of 'Rick and Morty' and NLP (Natural Language Processing). After watching the last episode of a mad scientist's and his grandson's adventures I realized that it's not a coincidence and I have to apply my knowledge in NLP and Machine Learning to create my own Rick (in a form of chat-bot, at least for now).\n",
        "\n",
        "![alt text](https://media.giphy.com/media/ZdBnIqBeVWBYTobH8U/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "The path to creating virtual Rick was not easy. I tried many models and approaches but virtual Rick did not want to find a common language with me for a long time. Rick's first response to my greeting was \"I am not your buddy\" (to tell you the truth, in the beginning he knew only this phrase). But I did not give up and with the help of excellent Transformers library and Microsoft's Large-scale Pretrained Response Generation Model (DialoGPT) I managed to talk heart-to-heart with Rick. Here is one of our conversations:\n",
        "\n",
        "**User**:Hey, Rick, make me a time machine <br>\n",
        "**RickBot**: You're a monster! <br>\n",
        "**User**:No, I just want to travel in time <br>\n",
        "**RickBot**: To the past. <br>\n",
        "**User**:yes <br>\n",
        "**RickBot**: No time machine, please. <br>\n",
        "**User**:But I need it <br>\n",
        "**RickBot**: You don't need it, Morty. Just do it. <br>\n",
        "**User**:I want to see antient Greece <br>\n",
        "**RickBot**: Oh, geez. <br>\n",
        "\n",
        "![alt text](https://media.giphy.com/media/WVGSfyhUYBoiGLbZ7N/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGJHOZYOWZHR"
      },
      "source": [
        "## A bit of theory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBd8PVGNWgfK"
      },
      "source": [
        "In this article I will tell you how to create a virtual character whose statements will be based on a transcript of my favorite animated science fiction sitcom. You can use characters and sitcoms of your choice. I added code to convert a regular text file with dialogs into a format that the model understands.\n",
        "\n",
        "As I already mentioned, [Transformers](https://huggingface.co/transformers/) library, which contains the latest NLP models (such as [BERT](https://huggingface.co/transformers/model_doc/bert.html), [XLNet](https://huggingface.co/transformers/model_doc/xlnet.html), [GPT-2](https://huggingface.co/transformers/model_doc/gpt2.html)) will help us in our task. You can read more about transformers in a beautifully illustrated [article](http://jalammar.github.io/illustrated-transformer/) by Jay Alammar.\n",
        "\n",
        "![alt text](http://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png) Image from[ http://jalammar.github.io](http://jalammar.github.io/illustrated-transformer/)\n",
        "\n",
        "Not so long ago, Microsoft’s [DialoGPT](https://huggingface.co/transformers/model_doc/dialogpt.html) was added to the Transformers model collection. DialoGPT is a GPT-2 model, trained on 147M multi-turn dialogue from Reddit discussion thread (you can learn more about GPT-2 [here](http://jalammar.github.io/illustrated-gpt2/)). This model is ideally suited for creating a virtual character for a fascinating conversation and even in the small implementation option it can maintain a coherent dialogue, which we will see now.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hyTyW7Le2Sb"
      },
      "source": [
        "## First dialogue with DialoGPT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEqpXb4ofFGd"
      },
      "source": [
        "We will conduct all our experiments in Google Colab, its resources are enough to train the small DialoGPT model. Firstly, we will connect to Google Drive and install the necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgL1yLLS09mP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9551b038-4418-43d1-950c-1353bb7260ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onU41i8g1J3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8452586-d64a-47fd-8418-76b08c88f504"
      },
      "source": [
        "! pip -q install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.3MB 32.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 50.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 44.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Y1XcsqgXBQ"
      },
      "source": [
        "Let's move to the desired folder in which we will store all our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHNacD0k1HI3"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVSTlysV2jaM"
      },
      "source": [
        "Try to chat with DialoGPT without fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6qrl7_SvPKg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314,
          "referenced_widgets": [
            "7c5e3d88b44b40b69cf0ae234c96993a",
            "71a6cfecb5d34054b823c1599eef6930",
            "5cc9dac7465841ad90b93b30aafa572c",
            "b72bd198f0f649528d2165b9e1ac90eb",
            "b2cf060b2af94c21bf659a81301070dd",
            "51bd8ec236b64eb89ea3a9cb3f277b53",
            "db3cd77ef1ea4c03b28de7348510a76c",
            "8b3febcd04e24568bf825434e6b3acfd",
            "0f5589a430bc45de80bd165ce81f305a",
            "5a1d16f6766e49cea610310ca85dcb6b",
            "7f49f0677bd342d18f08c0a74521bf70",
            "38f96a939f0243f39b1e8300123bcf44",
            "fed25d59cda34dc18d733301f9d8a8e9",
            "546c06b807ab4316936d8f6abf659ae1",
            "9e4750183de34f419c194321aae27a1c",
            "0052b4b9b7164007a9d753c898120416",
            "b68273caafc24f4abb0c7fcc05dc09cd",
            "0c9465ecfc4c4799a95ba1be32b49303",
            "a671c221ace8404cbd038d6d235a752e",
            "8917459b75bc45e0a531f3b74f269b40",
            "413000bbce49447aa6df57c40c9bdb3b",
            "7d70a2eeda98406f8b3daa1637d31739",
            "96c9010ea8e64274bc55636523285ec8",
            "0b35bceabb184f08910be674a2dbd07f",
            "44ca7868ae564a5287970401b0900f40",
            "675f031444a74397b0e73291db89e50e",
            "9cef977fccf04ba59cbce0fbd4bdf9ba",
            "de94a1f0690d4172b8467a7ccdf5a537",
            "e1d6cf576e1642ef82d116fa20ee3bc7",
            "1a9775e2f11540c6845e6aeaca6abbff",
            "cc1d946ed0864f428ef5566b9ad4c5ad",
            "d89875bccc0243869cbbc9f5dbe8682f",
            "0b8c1f8d9af04e8bb33a735853b65f63",
            "4aa00b564aa4426bb050b093b4092cfa",
            "e064a6b9f1504fd087f6d87e2f0fc837",
            "c54fccc393e64c7d9bd75ae593868ec2",
            "52e02cd3b1fb40a0961e3bd461a657eb",
            "baa2283fc5b74753a8d1c0dc15e20377",
            "990b6938625f434e9271cf48c2f59911",
            "82e170dc62624b298805f0c631b4af22"
          ]
        },
        "outputId": "18981672-5817-4daa-82ce-9cbb1c3600db"
      },
      "source": [
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-small\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c5e3d88b44b40b69cf0ae234c96993a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=641.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f5589a430bc45de80bd165ce81f305a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b68273caafc24f4abb0c7fcc05dc09cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44ca7868ae564a5287970401b0900f40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=26.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:810: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b8c1f8d9af04e8bb33a735853b65f63",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=351265583.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjZaN5ilgd-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da8209a-7d6d-42f3-d029-ab71d459fe3e"
      },
      "source": [
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens    \n",
        "    chat_history_ids = model.generate(\n",
        "    bot_input_ids, max_length=1000,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"DialoGPT: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> User:what is going on\n",
            "DialoGPT: I'm so confused\n",
            ">> User:i know this\n",
            "DialoGPT: I'm not sure what you're asking for.\n",
            ">> User:i am sure\n",
            "DialoGPT: I'm not sure what you're asking for\n",
            ">> User:i am so damn sure\n",
            "DialoGPT: I'm sure\n",
            ">> User:stop saying the same thing over and over again\n",
            "DialoGPT: I'm sure\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbzm0BHOitsa"
      },
      "source": [
        "**User:**Hi Rick <br> \n",
        "**DialoGPT:** Hi Rick <br>\n",
        "**User:**How are you? <br>\n",
        "**DialoGPT:** I'm good, how are you? <br>\n",
        "**User:**I am fine. Where is Morty? <br>\n",
        "**DialoGPT:** He's in the basement. <br>\n",
        "**User:**Who is Morty? <br>\n",
        "**DialoGPT:** He's a Morty. <br>\n",
        "**User:**Who are you? <br>\n",
        "**DialoGPT:** I am a Morty. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAy2OBMW6QyD"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/L3WevKXIKFDaZBvV8Q/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "Not bad but not too impressive. We will fix it with fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuzSROqxjUKM"
      },
      "source": [
        "## Model initial configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC3qNlfp30aU"
      },
      "source": [
        "Let's train our own Rick chatbot. For start, we will need basic configuration and a dataset.\n",
        "Configuration and training scripts are mostly based on this [script](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) from Huggingface and great [tutorial](https://nathancooper.io/i-am-a-nerd/chatbot/deep-learning/gpt2/2020/05/12/chatbot-part-1.html) from Nathan Cooper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g91QzdqU2haO"
      },
      "source": [
        "\"\"\"\n",
        "Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n",
        "GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n",
        "using a masked language modeling (MLM) loss.\n",
        "\"\"\"\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm.notebook import tqdm, trange\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from transformers import (\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter\n",
        "\n",
        "# Configs\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utprDGf06OVt"
      },
      "source": [
        "# Args to allow for easy convertion of python script to notebook\n",
        "class Args():\n",
        "    def __init__(self):\n",
        "        self.output_dir = 'output-small'\n",
        "        self.model_type = 'gpt2'\n",
        "        self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
        "        self.config_name = 'microsoft/DialoGPT-small'\n",
        "        self.tokenizer_name = 'microsoft/DialoGPT-small'\n",
        "        self.cache_dir = 'cached'\n",
        "        self.block_size = 512\n",
        "        self.do_train = True\n",
        "        self.do_eval = True\n",
        "        self.evaluate_during_training = False\n",
        "        self.per_gpu_train_batch_size = 4\n",
        "        self.per_gpu_eval_batch_size = 4\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.learning_rate = 5e-5\n",
        "        self.weight_decay = 0.0\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.num_train_epochs = 3\n",
        "        self.max_steps = -1\n",
        "        self.warmup_steps = 0\n",
        "        self.logging_steps = 1000\n",
        "        self.save_steps = 3500\n",
        "        self.save_total_limit = None\n",
        "        self.eval_all_checkpoints = False\n",
        "        self.no_cuda = False\n",
        "        self.overwrite_output_dir = True\n",
        "        self.overwrite_cache = True\n",
        "        self.should_continue = False\n",
        "        self.seed = 42\n",
        "        self.local_rank = -1\n",
        "        self.fp16 = False\n",
        "        self.fp16_opt_level = 'O1'\n",
        "\n",
        "args = Args()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qYqlTe9yx2"
      },
      "source": [
        "## Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo718Zb-961e"
      },
      "source": [
        "Our dialogues dataset will be based on a dataset used in Andrada Olteanu's [article](https://www.kaggle.com/andradaolteanu/sentiment-analysis-rick-and-morty-scripts/) about Rick and Morty sentiment analysis. Big thanks to her work and also to Gabriel Hernandes, author of original [text dataset](https://github.com/ghhernandes/rickmorty-gan/tree/master/data)!\n",
        "\n",
        "![alt text](https://media.giphy.com/media/U6LOakQja88ImTnE6T/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "First of all we will use kaggle module to download needed dataset. You can read in more detail about module and how to get Kaggle API Token by this [link](https://github.com/Kaggle/kaggle-api). Or you can just download RickAndMortyScripts.csv file from [article](https://www.kaggle.com/andradaolteanu/sentiment-analysis-rick-and-morty-scripts/) and place this file in your working directory. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbB-56mmm-rL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "cfa608df-6df4-4f06-d5fb-b69f194aa05a"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6L4u8_neZf"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-HczUyTnyzh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9e7bcab3-e128-4b93-e6c5-b1f326a5e227"
      },
      "source": [
        "!kaggle datasets download andradaolteanu/rickmorty-scripts -f RickAndMortyScripts.csv "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets%2F506221%2F935855%2FRickAndMortyScripts.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivUgcYk5r_Ff"
      },
      "source": [
        "!mv datasets%2F506221%2F935855%2FRickAndMortyScripts.csv RickAndMortyScripts.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxHdyv67dptm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e05c0491-bb52-4d1e-b575-fb8583f3bee2"
      },
      "source": [
        "# Let's look at original dataset\n",
        "all_rick = pd.read_csv('RickAndMortyScripts.csv')\n",
        "all_rick.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>season no.</th>\n",
              "      <th>episode no.</th>\n",
              "      <th>episode name</th>\n",
              "      <th>name</th>\n",
              "      <th>line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>Morty! You gotta come on. Jus'... you gotta co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Morty</td>\n",
              "      <td>What, Rick? What’s going on?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>I got a surprise for you, Morty.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Morty</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Morty</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Morty</td>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Pilot</td>\n",
              "      <td>Rick</td>\n",
              "      <td>Morty. I had to... I had to do it. I had— I ha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  season no.  ...   name                                               line\n",
              "0      0           1  ...   Rick  Morty! You gotta come on. Jus'... you gotta co...\n",
              "1      1           1  ...  Morty                       What, Rick? What’s going on?\n",
              "2      2           1  ...   Rick                   I got a surprise for you, Morty.\n",
              "3      3           1  ...  Morty  It's the middle of the night. What are you tal...\n",
              "4      4           1  ...   Rick  Come on, I got a surprise for you.  Come on, h...\n",
              "5      5           1  ...  Morty                Ow! Ow! You're tugging me too hard!\n",
              "6      6           1  ...   Rick  We gotta go, gotta get outta here, come on. Go...\n",
              "7      7           1  ...   Rick  What do you think of this... flying vehicle, M...\n",
              "8      8           1  ...  Morty  Yeah, Rick... I-it's great. Is this the surprise?\n",
              "9      9           1  ...   Rick  Morty. I had to... I had to do it. I had— I ha...\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51hsl2mAG8v"
      },
      "source": [
        "We will convert this dataset in a way that every responce row will contain **n** previous responces as a context. For our purposes seven previous responces will be enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyL7Dx1bbLRC"
      },
      "source": [
        "contexted = []\n",
        "\n",
        "n = 7\n",
        "\n",
        "for i in range(n, len(all_rick['line'])):\n",
        "  row = []\n",
        "  prev = i - 1 - n # we additionally substract 1, so row will contain current responce and 7 previous responces  \n",
        "  for j in range(i, prev, -1):\n",
        "    row.append(all_rick['line'][j])\n",
        "  contexted.append(row)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_cwbBolVi14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "35f4bab3-7550-4cb8-ce65-ec955504b418"
      },
      "source": [
        "len(contexted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1898"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNkYLty-VhTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "4016f588-033d-4a21-baf8-94b43c78431a"
      },
      "source": [
        "columns = ['response', 'context'] \n",
        "columns = columns + ['context/'+str(i) for i in range(n-1)]\n",
        "columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['response',\n",
              " 'context',\n",
              " 'context/0',\n",
              " 'context/1',\n",
              " 'context/2',\n",
              " 'context/3',\n",
              " 'context/4',\n",
              " 'context/5']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPafxqIYgurW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "d7302ee4-ca4d-4c41-aeea-6eb87a6f0f51"
      },
      "source": [
        "df = pd.DataFrame.from_records(contexted, columns=columns)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "      <th>context/0</th>\n",
              "      <th>context/1</th>\n",
              "      <th>context/2</th>\n",
              "      <th>context/3</th>\n",
              "      <th>context/4</th>\n",
              "      <th>context/5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "      <td>I got a surprise for you, Morty.</td>\n",
              "      <td>What, Rick? What’s going on?</td>\n",
              "      <td>Morty! You gotta come on. Jus'... you gotta co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "      <td>I got a surprise for you, Morty.</td>\n",
              "      <td>What, Rick? What’s going on?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Morty. I had to... I had to do it. I had— I ha...</td>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "      <td>I got a surprise for you, Morty.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What?! A bomb?!</td>\n",
              "      <td>Morty. I had to... I had to do it. I had— I ha...</td>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "      <td>It's the middle of the night. What are you tal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We're gonna drop it down there just get a whol...</td>\n",
              "      <td>What?! A bomb?!</td>\n",
              "      <td>Morty. I had to... I had to do it. I had— I ha...</td>\n",
              "      <td>Yeah, Rick... I-it's great. Is this the surprise?</td>\n",
              "      <td>What do you think of this... flying vehicle, M...</td>\n",
              "      <td>We gotta go, gotta get outta here, come on. Go...</td>\n",
              "      <td>Ow! Ow! You're tugging me too hard!</td>\n",
              "      <td>Come on, I got a surprise for you.  Come on, h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            response  ...                                          context/5\n",
              "0  What do you think of this... flying vehicle, M...  ...  Morty! You gotta come on. Jus'... you gotta co...\n",
              "1  Yeah, Rick... I-it's great. Is this the surprise?  ...                       What, Rick? What’s going on?\n",
              "2  Morty. I had to... I had to do it. I had— I ha...  ...                   I got a surprise for you, Morty.\n",
              "3                                    What?! A bomb?!  ...  It's the middle of the night. What are you tal...\n",
              "4  We're gonna drop it down there just get a whol...  ...  Come on, I got a surprise for you.  Come on, h...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBeM8pvEjigq"
      },
      "source": [
        "Split our dataset into a training and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1CeutVVlL85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "03b2aa56-5be3-4144-b10f-a52fce660dbb"
      },
      "source": [
        "trn_df, val_df = train_test_split(df, test_size = 0.1)\n",
        "trn_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "      <th>context/0</th>\n",
              "      <th>context/1</th>\n",
              "      <th>context/2</th>\n",
              "      <th>context/3</th>\n",
              "      <th>context/4</th>\n",
              "      <th>context/5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Wow. Well, okay, Jessica. L-let's give this a ...</td>\n",
              "      <td>Squeeze them. Manhandle them. Give them the bu...</td>\n",
              "      <td>Rename them?</td>\n",
              "      <td>Do you know what I want you to do with them?</td>\n",
              "      <td>Uh, that's flattering... and a little weird.</td>\n",
              "      <td>You know what I named these? My little Morties.</td>\n",
              "      <td>Wow. Th-they're both great. Thank you!</td>\n",
              "      <td>Can I show these to you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>I beg your pardon, Rick, INAPPROPRIATE.</td>\n",
              "      <td>I should get her pregnant, then she'll have to...</td>\n",
              "      <td>Ahhh, well,  I remember feeling that way about...</td>\n",
              "      <td>You're missing the point, Dad. I don't want gi...</td>\n",
              "      <td>Eh, Try not to worry about it, Morty. You're a...</td>\n",
              "      <td>I throw balls far. You want good words, date a...</td>\n",
              "      <td>Gee, thanks, Brad.</td>\n",
              "      <td>Dude, Stay in your league! Look at how hot she...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>768</th>\n",
              "      <td>Uh, w-why don't you get it Jerry? you're the m...</td>\n",
              "      <td>Jerry, get a job.</td>\n",
              "      <td>The trick to cereal is keeping 70% of it above...</td>\n",
              "      <td>Yeah, that's him. Hey, man, remember me?  I go...</td>\n",
              "      <td>There he is, there he is, there he is, there h...</td>\n",
              "      <td>Come on, man, it's this way...</td>\n",
              "      <td>I told you past the dinosaurs.</td>\n",
              "      <td>Hey man, when the hell were you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1750</th>\n",
              "      <td>Oh! S-sorry, I was expecting--</td>\n",
              "      <td>You don’t pay me to have faith! And we’re the ...</td>\n",
              "      <td>Maybe you should find a little faith, young man.</td>\n",
              "      <td>You shouldn’t, sir. You should be terrified.</td>\n",
              "      <td>I feel pretty confident about tonight’s debate.</td>\n",
              "      <td>We had a good run, sir, but I think it’s time ...</td>\n",
              "      <td>And the chemical that makes his brain secrete ...</td>\n",
              "      <td>We captured that moment and run it on a loop t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1623</th>\n",
              "      <td>If you lay those deaths at my doorstep one mor...</td>\n",
              "      <td>I'm not the one that didn't want you back. Ala...</td>\n",
              "      <td>You know,  I could have made a device to detec...</td>\n",
              "      <td>Oh, o-okay. This again?</td>\n",
              "      <td>Doomnomitron was hiding here! He's a shapeshif...</td>\n",
              "      <td>W-Wait, huh?</td>\n",
              "      <td>Nothing?! We exterminated a planet!</td>\n",
              "      <td>Nothing!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               response  ...                                          context/5\n",
              "63    Wow. Well, okay, Jessica. L-let's give this a ...  ...                           Can I show these to you?\n",
              "471             I beg your pardon, Rick, INAPPROPRIATE.  ...  Dude, Stay in your league! Look at how hot she...\n",
              "768   Uh, w-why don't you get it Jerry? you're the m...  ...                   Hey man, when the hell were you?\n",
              "1750                     Oh! S-sorry, I was expecting--  ...  We captured that moment and run it on a loop t...\n",
              "1623  If you lay those deaths at my doorstep one mor...  ...                                           Nothing!\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86F3WhnFO4H8"
      },
      "source": [
        "Now will convert our dataset in a format suitable for our model. Basically we will concatenate responses in one string for each row (additionally we will add special 'end of string' token between responses, so the model will understand end of each response in a string).  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX7jeWpYmOe_"
      },
      "source": [
        "def construct_conv(row, tokenizer, eos = True):\n",
        "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n",
        "    conv = flatten(conv)\n",
        "    return conv\n",
        "\n",
        "class ConversationDataset(Dataset):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n",
        "\n",
        "        block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\n",
        "\n",
        "        directory = args.cache_dir\n",
        "        cached_features_file = os.path.join(\n",
        "            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n",
        "        )\n",
        "\n",
        "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
        "            logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"rb\") as handle:\n",
        "                self.examples = pickle.load(handle)\n",
        "        else:\n",
        "            logger.info(\"Creating features from dataset file at %s\", directory)\n",
        "\n",
        "            self.examples = []\n",
        "            for _, row in df.iterrows():\n",
        "                conv = construct_conv(row, tokenizer)\n",
        "                self.examples.append(conv)\n",
        "\n",
        "            logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "            with open(cached_features_file, \"wb\") as handle:\n",
        "                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return torch.tensor(self.examples[item], dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naaRHoXgnStq"
      },
      "source": [
        "# Cacheing and storing of data/checkpoints\n",
        "\n",
        "def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n",
        "    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n",
        "\n",
        "\n",
        "def set_seed(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "\n",
        "def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n",
        "    ordering_and_checkpoint_path = []\n",
        "\n",
        "    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n",
        "\n",
        "    for path in glob_checkpoints:\n",
        "        if use_mtime:\n",
        "            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n",
        "        else:\n",
        "            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n",
        "            if regex_match and regex_match.groups():\n",
        "                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n",
        "\n",
        "    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n",
        "    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n",
        "    return checkpoints_sorted\n",
        "\n",
        "\n",
        "def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n",
        "    if not args.save_total_limit:\n",
        "        return\n",
        "    if args.save_total_limit <= 0:\n",
        "        return\n",
        "\n",
        "    # Check if we should delete older checkpoint(s)\n",
        "    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n",
        "    if len(checkpoints_sorted) <= args.save_total_limit:\n",
        "        return\n",
        "\n",
        "    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n",
        "    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n",
        "    for checkpoint in checkpoints_to_be_deleted:\n",
        "        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n",
        "        shutil.rmtree(checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkvMNnrnVHQw"
      },
      "source": [
        "## Training and Evaluating\n",
        "\n",
        "There will be quite a lot of code needed for training our model but don’t worry, everything should work as is, the main thing is to give the model the dataset in the right format.\n",
        "\n",
        "![alt text](https://media.giphy.com/media/KetvQljQJdEMscR83K/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXzKlXHeu0Mb"
      },
      "source": [
        "def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer = SummaryWriter()\n",
        "\n",
        "    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n",
        "\n",
        "    def collate(examples: List[torch.Tensor]):\n",
        "        if tokenizer._pad_token is None:\n",
        "            return pad_sequence(examples, batch_first=True)\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n",
        "    )\n",
        "\n",
        "    if args.max_steps > 0:\n",
        "        t_total = args.max_steps\n",
        "        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n",
        "    else:\n",
        "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    # add_special_tokens_(model, tokenizer)\n",
        "\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Check if saved optimizer or scheduler states exist\n",
        "    if (\n",
        "        args.model_name_or_path\n",
        "        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n",
        "        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n",
        "    ):\n",
        "        # Load in optimizer and scheduler states\n",
        "        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n",
        "        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n",
        "\n",
        "    if args.fp16:\n",
        "        try:\n",
        "            from apex import amp\n",
        "        except ImportError:\n",
        "            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
        "\n",
        "    # multi-gpu training (should be after apex fp16 initialization)\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Distributed training (should be after apex fp16 initialization)\n",
        "    if args.local_rank != -1:\n",
        "        model = torch.nn.parallel.DistributedDataParallel(\n",
        "            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n",
        "        )\n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n",
        "    logger.info(\n",
        "        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps\n",
        "        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n",
        "    )\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    epochs_trained = 0\n",
        "    steps_trained_in_current_epoch = 0\n",
        "    # Check if continuing training from a checkpoint\n",
        "    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n",
        "        try:\n",
        "            # set global_step to gobal_step of last saved checkpoint from model path\n",
        "            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n",
        "            global_step = int(checkpoint_suffix)\n",
        "            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n",
        "\n",
        "            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n",
        "            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n",
        "            logger.info(\"  Continuing training from global step %d\", global_step)\n",
        "            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n",
        "        except ValueError:\n",
        "            logger.info(\"  Starting fine-tuning.\")\n",
        "\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "\n",
        "    model.zero_grad()\n",
        "    train_iterator = trange(\n",
        "        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n",
        "    )\n",
        "    set_seed(args)  # Added here for reproducibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "\n",
        "            # Skip past any already trained steps if resuming training\n",
        "            if steps_trained_in_current_epoch > 0:\n",
        "                steps_trained_in_current_epoch -= 1\n",
        "                continue\n",
        "\n",
        "            inputs, labels = (batch, batch)\n",
        "            if inputs.shape[1] > 1024: continue\n",
        "            inputs = inputs.to(args.device)\n",
        "            labels = labels.to(args.device)\n",
        "            model.train()\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "\n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "            if args.fp16:\n",
        "                with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "                    scaled_loss.backward()\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "                if args.fp16:\n",
        "                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    # Log metrics\n",
        "                    if (\n",
        "                        args.local_rank == -1 and args.evaluate_during_training\n",
        "                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer)\n",
        "                        for key, value in results.items():\n",
        "                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n",
        "                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n",
        "                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    checkpoint_prefix = \"checkpoint\"\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n",
        "                    os.makedirs(output_dir, exist_ok=True)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )  # Take care of distributed/parallel training\n",
        "                    model_to_save.save_pretrained(output_dir)\n",
        "                    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "                    _rotate_checkpoints(args, checkpoint_prefix)\n",
        "\n",
        "                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
        "                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
        "                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n",
        "\n",
        "            if args.max_steps > 0 and global_step > args.max_steps:\n",
        "                epoch_iterator.close()\n",
        "                break\n",
        "        if args.max_steps > 0 and global_step > args.max_steps:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    if args.local_rank in [-1, 0]:\n",
        "        tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step\n",
        "\n",
        "# Evaluation of some model\n",
        "\n",
        "def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n",
        "    # Loop to handle MNLI double evaluation (matched, mis-matched)\n",
        "    eval_output_dir = args.output_dir\n",
        "\n",
        "    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n",
        "    os.makedirs(eval_output_dir, exist_ok=True)\n",
        "    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n",
        "    # Note that DistributedSampler samples randomly\n",
        "\n",
        "    def collate(examples: List[torch.Tensor]):\n",
        "        if tokenizer._pad_token is None:\n",
        "            return pad_sequence(examples, batch_first=True)\n",
        "        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n",
        "    )\n",
        "\n",
        "    # multi-gpu evaluate\n",
        "    if args.n_gpu > 1:\n",
        "        model = torch.nn.DataParallel(model)\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    model.eval()\n",
        "\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        inputs, labels = (batch, batch)\n",
        "        inputs = inputs.to(args.device)\n",
        "        labels = labels.to(args.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs, labels=labels)\n",
        "            lm_loss = outputs[0]\n",
        "            eval_loss += lm_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    perplexity = torch.exp(torch.tensor(eval_loss))\n",
        "\n",
        "    result = {\"perplexity\": perplexity}\n",
        "\n",
        "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MGD6bFXV4Z-"
      },
      "source": [
        "# Main runner\n",
        "\n",
        "def main(df_trn, df_val):\n",
        "    args = Args()\n",
        "    \n",
        "    if args.should_continue:\n",
        "        sorted_checkpoints = _sorted_checkpoints(args)\n",
        "        if len(sorted_checkpoints) == 0:\n",
        "            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n",
        "        else:\n",
        "            args.model_name_or_path = sorted_checkpoints[-1]\n",
        "\n",
        "    if (\n",
        "        os.path.exists(args.output_dir)\n",
        "        and os.listdir(args.output_dir)\n",
        "        and args.do_train\n",
        "        and not args.overwrite_output_dir\n",
        "        and not args.should_continue\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n",
        "                args.output_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Setup CUDA, GPU & distributed training\n",
        "    device = torch.device(\"cuda\")\n",
        "    args.n_gpu = torch.cuda.device_count()\n",
        "    args.device = device\n",
        "\n",
        "    # Setup logging\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
        "    )\n",
        "    logger.warning(\n",
        "        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "        args.local_rank,\n",
        "        device,\n",
        "        args.n_gpu,\n",
        "        bool(args.local_rank != -1),\n",
        "        args.fp16,\n",
        "    )\n",
        "\n",
        "    # Set seed\n",
        "    set_seed(args)\n",
        "\n",
        "    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n",
        "    model = AutoModelWithLMHead.from_pretrained(\n",
        "        args.model_name_or_path,\n",
        "        from_tf=False,\n",
        "        config=config,\n",
        "        cache_dir=args.cache_dir,\n",
        "    )\n",
        "    model.to(args.device)\n",
        "    \n",
        "    logger.info(\"Training/evaluation parameters %s\", args)\n",
        "\n",
        "    # Training\n",
        "    if args.do_train:\n",
        "        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n",
        "\n",
        "        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n",
        "    if args.do_train:\n",
        "        # Create output directory if needed\n",
        "        os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "        # They can then be reloaded using `from_pretrained()`\n",
        "        model_to_save = (\n",
        "            model.module if hasattr(model, \"module\") else model\n",
        "        )  # Take care of distributed/parallel training\n",
        "        model_to_save.save_pretrained(args.output_dir)\n",
        "        tokenizer.save_pretrained(args.output_dir)\n",
        "\n",
        "        # Good practice: save your training arguments together with the trained model\n",
        "        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "        # Load a trained model and vocabulary that you have fine-tuned\n",
        "        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
        "        model.to(args.device)\n",
        "\n",
        "    # Evaluation\n",
        "    results = {}\n",
        "    if args.do_eval and args.local_rank in [-1, 0]:\n",
        "        checkpoints = [args.output_dir]\n",
        "        if args.eval_all_checkpoints:\n",
        "            checkpoints = list(\n",
        "                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n",
        "            )\n",
        "            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n",
        "        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "        for checkpoint in checkpoints:\n",
        "            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "\n",
        "            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n",
        "            model.to(args.device)\n",
        "            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n",
        "            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "            results.update(result)\n",
        "\n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZEHDzR0Vjs7"
      },
      "source": [
        "It is time to train our model!\n",
        "\n",
        "![alt text](https://media.giphy.com/media/Tia3dkakIp2m4uGoDI/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__iqR8YFV-Ex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5aab8b98fdf741428fda6a2936a6c32b",
            "b581bbe998324e4198b54f1b33fa8fcb",
            "ff9f00d7a67b4a0d944299166c3943e5",
            "0bc945b69eff441db1bb7be22c0896f9",
            "475d496b15b343448e7463cdcf9463a4",
            "e34e242a73ac4f4887f3d16d651affdf",
            "b2c9710105a6405f9de235c41ed39a50",
            "62d6b4a4ad454316bcceb04ecb55821b",
            "8e1d23ba00644b80b8b4b5ee6a5abb6b",
            "4f3f630db29349da9afb5b7479f4aaf2",
            "b69f24d60bfe4bd7a50cb9465505e0dc",
            "74fad213012043dcaa370dc2e54de8bc",
            "4bf0d712c8564501b202165d1e0033d5",
            "19f2b118a7db4bc292c06d94c2760590",
            "ee6446c4023c48518fd58b833e1a594e",
            "c99fa5c01fe4478aa8e57b7d59e11c29",
            "136a63d66eb44cccbcd66bf4c0535a6b",
            "b1b239d3d3f14906934461eb66c1c0f6",
            "f326022eebe1428daab12fab05c8a075",
            "c4091ab4f5264a86a149793853dbb941",
            "a0f8864b0bf74deab8240b716dbda564",
            "3cb73064ba3545d0815cef04dba25f40",
            "c6fa8a5e40b74a4199ab785729880b39",
            "57b31670fc3a40839a6004c6aa0e41a5",
            "c2109878b39849a799187136beadf144",
            "36d501a1ff37420eadef5bcd7297ee26",
            "0a76fe2605c84745b42f9cdb5f1a52db",
            "2dfb4d0fc09645118f830e4ebc5dfdd0",
            "f5b6f22c0ea24860a93cbe6a6edfc05e",
            "69bbca8e234e48fbbc389fd44e11624f",
            "02bc54995de148238eb5ed06f2ea8d62",
            "270e2a3848324fb5996af60d6ef26366",
            "6296e303aed34c01866caffc200c0cfb",
            "60eabd58645142aea72ae027b057d65d",
            "9d9f452aa79048599819ad5cc759a5e5",
            "d4e4ccce098941459c4409187201979d",
            "d57f56580d244a59ad388adb33abcb4d",
            "37e11da84adb4832842d9a9ce54c2c2b",
            "822d24db536f4994af65dd764364695c",
            "1391f67de61c40f1aa24fd267c1f70d9"
          ]
        },
        "outputId": "c14014a0-271a-452d-d282-db2bf50a6589"
      },
      "source": [
        "main(trn_df, val_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "06/07/2020 12:50:27 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "06/07/2020 12:50:28 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n",
            "06/07/2020 12:50:28 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "06/07/2020 12:50:28 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/config.json from cache at cached/c3a09526c725b854c685b72cf60c50f1fea9b0e4d6227fa41573425ef4bd4bc6.4c1d7fc2ac6ddabeaf0c8bec2ffc7dc112f668f5871a06efcff113d2797ec7d5\n",
            "06/07/2020 12:50:28 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "06/07/2020 12:50:28 - INFO - transformers.tokenization_utils -   Model name 'microsoft/DialoGPT-small' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'microsoft/DialoGPT-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "06/07/2020 12:50:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/vocab.json from cache at cached/78725a31b87003f46d5bffc3157ebd6993290e4cfb7002b5f0e52bb0f0d9c2dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "06/07/2020 12:50:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/merges.txt from cache at cached/570e31eddfc57062e4d0c5b078d44f97c0e5ac48f83a2958142849b59df6bbe6.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "06/07/2020 12:50:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/added_tokens.json from cache at None\n",
            "06/07/2020 12:50:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/special_tokens_map.json from cache at None\n",
            "06/07/2020 12:50:30 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/DialoGPT-small/tokenizer_config.json from cache at None\n",
            "06/07/2020 12:50:32 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/microsoft/DialoGPT-small/pytorch_model.bin from cache at cached/9eab12d0b721ee394e9fe577f35d9b8b22de89e1d4f6a89b8a76d6e1a82bceae.906a78bee3add2ff536ac7ef16753bb3afb3a1cf8c26470f335b7c0e46a21483\n",
            "06/07/2020 12:50:44 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias']\n",
            "06/07/2020 12:50:58 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7f9f14477cf8>\n",
            "06/07/2020 12:50:58 - INFO - __main__ -   Creating features from dataset file at cached\n",
            "06/07/2020 12:51:01 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n",
            "06/07/2020 12:51:02 - INFO - __main__ -   ***** Running training *****\n",
            "06/07/2020 12:51:02 - INFO - __main__ -     Num examples = 1708\n",
            "06/07/2020 12:51:02 - INFO - __main__ -     Num Epochs = 3\n",
            "06/07/2020 12:51:02 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
            "06/07/2020 12:51:02 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "06/07/2020 12:51:02 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "06/07/2020 12:51:02 - INFO - __main__ -     Total optimization steps = 1281\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5aab8b98fdf741428fda6a2936a6c32b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e1d23ba00644b80b8b4b5ee6a5abb6b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=427.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "136a63d66eb44cccbcd66bf4c0535a6b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=427.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2109878b39849a799187136beadf144",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=427.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "06/07/2020 13:02:37 - INFO - __main__ -    global_step = 1281, average loss = 2.010103105102825\n",
            "06/07/2020 13:02:37 - INFO - __main__ -   Saving model checkpoint to output-small3\n",
            "06/07/2020 13:02:37 - INFO - transformers.configuration_utils -   Configuration saved in output-small3/config.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "06/07/2020 13:02:39 - INFO - transformers.modeling_utils -   Model weights saved in output-small3/pytorch_model.bin\n",
            "06/07/2020 13:02:39 - INFO - transformers.configuration_utils -   loading configuration file output-small3/config.json\n",
            "06/07/2020 13:02:39 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "06/07/2020 13:02:39 - INFO - transformers.modeling_utils -   loading weights file output-small3/pytorch_model.bin\n",
            "06/07/2020 13:02:46 - INFO - transformers.configuration_utils -   loading configuration file output-small3/config.json\n",
            "06/07/2020 13:02:46 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "06/07/2020 13:02:46 - INFO - transformers.tokenization_utils -   Model name 'output-small3' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output-small3' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "06/07/2020 13:02:46 - INFO - transformers.tokenization_utils -   Didn't find file output-small3/added_tokens.json. We won't load it.\n",
            "06/07/2020 13:02:46 - INFO - transformers.tokenization_utils -   loading file output-small3/vocab.json\n",
            "06/07/2020 13:02:46 - INFO - transformers.tokenization_utils -   loading file output-small3/merges.txt\n",
            "06/07/2020 13:02:46 - INFO - transformers.tokenization_utils -   loading file None\n",
            "06/07/2020 13:02:46 - INFO - transformers.tokenization_utils -   loading file output-small3/special_tokens_map.json\n",
            "06/07/2020 13:02:46 - INFO - transformers.tokenization_utils -   loading file output-small3/tokenizer_config.json\n",
            "06/07/2020 13:02:46 - INFO - __main__ -   Evaluate the following checkpoints: ['output-small3']\n",
            "06/07/2020 13:02:46 - INFO - transformers.configuration_utils -   loading configuration file output-small3/config.json\n",
            "06/07/2020 13:02:46 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "06/07/2020 13:02:46 - INFO - transformers.modeling_utils -   loading weights file output-small3/pytorch_model.bin\n",
            "06/07/2020 13:02:53 - INFO - __main__ -   Creating features from dataset file at cached\n",
            "06/07/2020 13:02:54 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n",
            "06/07/2020 13:02:54 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "06/07/2020 13:02:54 - INFO - __main__ -     Num examples = 190\n",
            "06/07/2020 13:02:54 - INFO - __main__ -     Batch size = 4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6296e303aed34c01866caffc200c0cfb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=47.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "06/07/2020 13:03:02 - INFO - __main__ -   ***** Eval results  *****\n",
            "06/07/2020 13:03:02 - INFO - __main__ -     perplexity = tensor(3.8291)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'perplexity_': tensor(3.8291)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eDkPEuvbD47"
      },
      "source": [
        "## Chatting with  Rick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjVqotI05gOS"
      },
      "source": [
        "The model is ready, so it's time to chat with Rick. But don't forget that Rick can be rude, I warned you.\n",
        "\n",
        "A variety of methods can be used in responces generation. You can find more details about these methods by this [link](https://huggingface.co/blog/how-to-generate). \n",
        "\n",
        "![alt text](https://media.giphy.com/media/ftl8NiWz2C3tuXOn3w/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIeqMwZktv7N"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
        "model = AutoModelWithLMHead.from_pretrained('output-small')\n",
        "\n",
        "# Let's chat for 5 lines\n",
        "for step in range(5):\n",
        "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
        "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
        "    # print(new_user_input_ids)\n",
        "\n",
        "    # append the new user input tokens to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
        "\n",
        "    # generated a response while limiting the total chat history to 1000 tokens, \n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids, max_length=200,\n",
        "        pad_token_id=tokenizer.eos_token_id,  \n",
        "        no_repeat_ngram_size=3,       \n",
        "        do_sample=True, \n",
        "        top_k=100, \n",
        "        top_p=0.7,\n",
        "        temperature = 0.8\n",
        "    )\n",
        "    \n",
        "    # pretty print last ouput tokens from bot\n",
        "    print(\"RickBot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zq2wJFtss1e"
      },
      "source": [
        "**User**:How are you, Rick? <br>\n",
        "**RickBot**: I'm fine. <br>\n",
        "**User**:Where is Morty? <br>\n",
        "**RickBot**: He's in a hospital. <br>\n",
        "**User**:Why? <br>\n",
        "**RickBot**: Well, that depends on who breaks first -- me or the hospital. I mean, you know, the one that keeps giving me pills. <br>\n",
        "**User**:I don't understand <br>\n",
        "**RickBot**: Whoa! Whoa! <br>\n",
        "**User**:I see, you took your pills <br>\n",
        "**RickBot**: Hey, I-I'm not proud of this. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvxnAOkTBTIJ"
      },
      "source": [
        "I will give an example of a few more dialogues to show how Ricky is our Rick now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1gX23iKkd0g"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/eNpXWzGIMRjIo4lXT8/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "**User**:Who are you? <br>\n",
        "**RickBot**: A musician, I'm not a musician, but I'm pretty close to you. <br>\n",
        "**User**:What kind of musician are you? <br>\n",
        "**RickBot**: Who cares? I'm a musician. <br>\n",
        "**User**:Ok, play a song for me <br>\n",
        "**RickBot**: Shut up and listen to me, Morty. Listen to me. Listen! I'm the leader of a bunch of different death worlds, and I'm just trying to assemble a band. I'm gonna make this one-piece, and you're gonna be part of it. <br>\n",
        "**User**:ok <br>\n",
        "**RickBot**: Whoa, whoa, hey, who's this? <br>\n",
        "**User**:This is Morty <br>\n",
        "**RickBot**: Geez!!! <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDiz2J0LBqaq"
      },
      "source": [
        "![alt text](https://i.kym-cdn.com/news/posts/desktop/000/000/247/Screenshot_21.jpg)\n",
        "\n",
        "Image from [news.knowyourmeme.com](https://news.knowyourmeme.com/news/elon-musks-rick-and-morty-cameo-is-a-meme-reference)\n",
        "\n",
        "**User**:What do you think about Elon Musk? <br>\n",
        "**RickBot**: I think about him a lot. <br>\n",
        "**User**:But what exactly do you think? <br>\n",
        "**RickBot**: He's not a bad guy. He's just... not a very charismatic one. <br>\n",
        "**User**:I think he is charismatic <br>\n",
        "**RickBot**: He is. <br>\n",
        "**User**:What else you can say about him? <br>\n",
        "**RickBot**: You don't have to say anything. He is the leader of your class. <br>\n",
        "**User**:ok, thank you <br>\n",
        "**RickBot**: !!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezq6Qtl_3NtD"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/YSTmV6MWEkgW0HblZQ/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "**User**:hey, go get me a burger <br>\n",
        "RickBot: Whoa, whoa, hold on a second, let's not get crazy. This is gonna be good. <br>\n",
        "**User**:I'm hungry! c'mon, buy me a burger or better two <br>\n",
        "**RickBot**: Holy crap. <br>\n",
        "**User**:no crappy burger, a good one! <br>\n",
        "**RickBot**: What the hell? <br>\n",
        "**User**:don't be so bad, feed me <br>\n",
        "**RickBot**: I'll be back as fast as I can, Morty. <br>\n",
        "**User**:good boy, and don't forget ketchup and fries <br>\n",
        "**RickBot**: !!!!!! <br>\n",
        "**User**:what a hell? can you reply with words? <br>\n",
        "**RickBot**: Yes!! I will!! We will go out on a date. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Woi683Eyvttc"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZmkXDkv4BAl"
      },
      "source": [
        "![alt text](https://media.giphy.com/media/YQBWwGLJtFDQIATck5/giphy.gif)\n",
        "\n",
        "Image from [Giphy](https://giphy.com/)\n",
        "\n",
        "Congratulations! Our virtual Rick is alive (almost)! With the help of fine-tuning our model on a small dataset, we were able to create a virtual character with whom we can conduct interesting dialogs. \n",
        "\n",
        "Using the proposed approach you can create many interesting virtual characters based on an arbitrary dialogs dataset (just a csv file with replicas, one replica per line)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jAMH0XPuE-f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjd1pCZxukWh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofg7iJNFyjBs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}